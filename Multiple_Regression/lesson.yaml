- Class: meta
  Course: DS705
  Lesson: Multiple Regression
  Author: Dave Reineke
  Type: Standard
  Organization: University of Wisconsin - La Crosse
  Version: 2.2.0

#1
- Class: text
  Output: Let's go over some of the basics of multiple linear regression.  The HealthExam data set has been loaded and will be used to demonstrate a number of functions useful in multiple regression.  (Recall, you can type 'skip()' at any time to bypass a task, enter play() to put swirl on hold and experiment in R for while, enter nxt() to get back to the lesson).

#2
- Class: cmd_question
  Output: In regression, it is beneficial to look at plots first if at all possible.  Suppose we want to examine a multiple regression model to predict weight from height, waist, and systolic blood pressure. Enter pairs(Weight~Height+Waist+SysBP,data=HealthExam) at the command prompt to create a scatterplot matrix.  
  CorrectAnswer: pairs(Weight~Height+Waist+SysBP,data=HealthExam)
  AnswerTests:  omnitest(correctExpr='pairs(Weight~Height+Waist+SysBP,data=HealthExam)')
  Hint: Type or paste pairs(Weight~Height+Waist+SysBP,data=HealthExam) at the command prompt

#3
- Class: text
  Output: Since the response variable is in the top row, that is a good place to look first to see if there might be any linear relationships between weight and the other three variables. It is also a good idea to see if any of the potential predictor variables may be strongly related, in which case we would have a collinearity problem. Take a look at the plot, then proceed.
  
#4
- Class: cmd_question
  Output: To make a correlation matrix for these variables, we'll first pull just those variables from the data frame and put them in a matrix in order to avoid creating correlation matrix for all the variables in the set, which could be very large.  Enter mat <- cbind(HealthExam$Weight,HealthExam$Height,HealthExam$Waist,HealthExam$SysBP) at the prompt. 
  CorrectAnswer: mat <- cbind(HealthExam$Weight,HealthExam$Height,HealthExam$Waist,HealthExam$SysBP)
  AnswerTests:  omnitest(correctExpr='mat <- cbind(HealthExam$Weight,HealthExam$Height,HealthExam$Waist,HealthExam$SysBP)')
  Hint: Enter mat <- cbind(HealthExam$Weight,HealthExam$Height,HealthExam$Waist,HealthExam$SysBP) at the command prompt. 
  
#5
- Class: cmd_question
  Output: To get the correlation matrix, enter cor(mat) at the prompt. 
  CorrectAnswer: cor(mat)
  AnswerTests:  omnitest(correctExpr='cor(mat)')
  Hint: Enter cor(mat) at the command prompt.

#6
- Class: text
  Output: Note that we entered the variables so that they appear in the same order in the correlation matrix as in the scatterplot matrix. Are any correlations in the first row "large?" What about any of the other ones?  Is this what you expected from what you saw in the scatterplot matrix?  I'm not actually asking you to enter an answer - I just want you to think about these things.  When you're done thinking, press <enter>.

#7
- Class: cmd_question
  Output: Let's get to the regression!  To fit the first order linear model and store the output in an object, enter fit <- lm(Weight~Height+Waist+SysBP,HealthExam) at the command prompt.  
  CorrectAnswer: fit <- lm(Weight~Height+Waist+SysBP,HealthExam)
  AnswerTests:  omnitest(correctExpr='fit <- lm(Weight~Height+Waist+SysBP,HealthExam)')
  Hint: Type or paste fit <- lm(Weight~Height+Waist+SysBP,HealthExam) at the command prompt.

#8
- Class: cmd_question
  Output: To see the output for this model, enter summary(fit) at the command prompt.  You may need to scroll up to check out the p-values for each coefficient, the Multiple R-squared, and the Adjusted R-squared.  I love this part!
  CorrectAnswer: summary(fit)
  AnswerTests:  omnitest(correctExpr='summary(fit)')
  Hint: Type summary(fit) at the command prompt.

#9
- Class: cmd_question
  Output: Enter vif(fit) to see the Variance Inflation Factors.  This function requires the package HH, which was installed with this lesson (meaning that you would need to install it on your machine to use outside of this lesson).
  CorrectAnswer: vif(fit)
  AnswerTests:  omnitest(correctExpr='vif(fit)')
  Hint: Type vif(fit) at the command prompt.

#10
- Class: mult_question
  Output: Are all of the VIFs under 10?  
  AnswerChoices: yes; no
  CorrectAnswer: yes
  AnswerTests: omnitest(correctVal='yes')
  Hint: This should be an easy one.

#11
- Class: cmd_question
  Output: Create some standard residual plots, which are good for assessing model assumptions.  Enter plot(fit) at the command prompt.  You'll be asked to hit <Return> to display each plot in turn.  
  CorrectAnswer: plot(fit)
  AnswerTests:  omnitest(correctExpr='plot(fit)')
  Hint: Type plot(fit) at the command prompt.

#12
- Class: cmd_question
  Output: Hypothesis test can be used on residuals to assess model assumptions.  For example, to test the residuals for normality enter shapiro.test(fit$resid) at the command prompt.
  CorrectAnswer: shapiro.test(fit$resid)
  AnswerTests:  omnitest(correctExpr='shapiro.test(fit$resid)')
  Hint: Enter shapiro.test(fit$resid) at the command prompt. 

#13
- Class: cmd_question
  Output: Enter bptest(fit) to conduct the Bruesch-Pagan test for homogeneity of variance among the residuals.  This function requires the package lmtest, which was also installed with this lesson.
  CorrectAnswer: bptest(fit)
  AnswerTests:  omnitest(correctExpr='bptest(fit)')
  Hint: Type bptest(fit) at the command prompt.

#14
- Class: mult_question
  Output: At a 5% level of significance, does this test indicate that the error variances are not constant, as the model assumptions dictate?
  AnswerChoices: yes; no
  CorrectAnswer: no
  AnswerTests: omnitest(correctVal='no')
  Hint: Since the p-value is greater than 0.05, the null hypothesis of homogeneity is not rejected.

#15
- Class: cmd_question
  Output: Enter dwtest(fit) to conduct the Durbin-Watson test for serial correlation among the residuals.  This function also requires the package lmtest, which, as you know, was installed with this lesson.
  CorrectAnswer: dwtest(fit)
  AnswerTests:  omnitest(correctExpr='dwtest(fit)')
  Hint: Enter dwtest(fit) at the command prompt.

#16
- Class: mult_question
  Output: At a 5% level of significance, does this test indicate that the residuals are serially correlated (i.e. did the order of observations have some effect on the response)?
  AnswerChoices: yes; no
  CorrectAnswer: no
  AnswerTests: omnitest(correctVal='no')
  Hint: Since the p-value is greater than 0.05, the null hypothesis of serial independence is not rejected.

#17
- Class: text
  Output: There are several tests and statistics to examine residuals, they are beyond the scope of this lesson.  There is really no substitute for an examination of the residual plots; looking for patterns, outliers, and influential observations.

#18
- Class: cmd_question
  Output: Confidence intervals for the parameter estimates can be obtained by entering confint(fit) at the command prompt.  Go for it.  
  CorrectAnswer: confint(fit)
  AnswerTests:  omnitest(correctExpr='confint(fit)')
  Hint: Type confint(fit) at the command prompt.

#19
- Class: cmd_question
  Output: Suppose we want use this model to estimate the mean weight for all adults in the U.S. who are 65 inches in height, have an 80 cm waist circumference, and systolic BP of 115.  A new data frame for this set of values for the independent variable need to be made.  Do this by entering newdata <- data.frame(Height=65,Waist=80,SysBP=115) at the command prompt.
  CorrectAnswer: newdata <- data.frame(Height=65,Waist=80,SysBP=115)
  AnswerTests:  omnitest(correctExpr='newdata <- data.frame(Height=65,Waist=80,SysBP=115)')
  Hint: Type or paste newdata <- data.frame(Height=65,Waist=80,SysBP=115) at the command prompt.
  
#20
- Class: cmd_question
  Output: A confidence interval for the mean response for all adults in the U.S. who are 65 inches in height, have an 80 cm waist circumference, and systolic BP of 115 mm Hg can be found by entering predict.lm(fit,newdata,interval="confidence").
  CorrectAnswer: predict.lm(fit,newdata,interval="confidence")
  AnswerTests:  omnitest(correctExpr='predict.lm(fit,newdata,interval="confidence")')
  Hint: Enter predict.lm(fit,newdata,interval="confidence") at the command prompt.

#21
- Class: cmd_question
  Output: A prediction interval for the future individual response for a randomly selected adult in the U.S. who is 65 inches in height, has an 80 cm waist circumference, and systolic BP of 115 mmHg can be found by entering predict.lm(fit,newdata,interval="prediction").
  CorrectAnswer: predict.lm(fit,newdata,interval="prediction")
  AnswerTests:  omnitest(correctExpr='predict.lm(fit,newdata,interval="prediction")')
  Hint: Enter predict.lm(fit,newdata,interval="prediction") at the command prompt.
  
#22
- Class: text
  Output: The function to produce confidence and prediction intervals can be applied to the entire data set simply by typing predict.lm(fit,interval="confidence") or predict.lm(fit,interval="predict").  Not now, though.  Let's move on to the next thing - hit <enter>. 

#23
- Class: text
  Output: In order to test a subset of the independent variables, store the output for the "full" and "reduced" each in their own objects, then use the anova function.  We'll use the object we've already created as the full model.
  
#24
- Class: cmd_question
  Output: Suppose we want to test the the coefficients of Height and SysBP are both not zero.  The reduced model, if those coefficients were indeed both zero, would be obtained as fit2 <- lm(Weight~Waist,data=HealthExam).  Enter this code at the command prompt now. 
  CorrectAnswer: fit2 <- lm(Weight~Waist,data=HealthExam)
  AnswerTests:  omnitest(correctExpr='fit2 <- lm(Weight~Waist,data=HealthExam)')
  Hint: Enter fit2 <- lm(Weight~Waist,data=HealthExam) at the command prompt.

#25
- Class: cmd_question
  Output: To test the full model against the reduced model, enter anova(fit,fit2) at the command prompt.
  CorrectAnswer: anova(fit,fit2)
  AnswerTests:  omnitest(correctExpr='anova(fit,fit2)')
  Hint: Enter anova(fit,fit2) at the command prompt.
  
#26
- Class: text
  Output: According to that p-value, at least one of the coefficients is not zero.
  
#27
- Class: cmd_question
  Output: The AIC for the model that has been estimated can be produced by entering AIC(fit), at least in this case because we assigned the output to the object called "fit".  Do this for the linear model that we fit previously in this lesson. 
  CorrectAnswer: AIC(fit)
  AnswerTests:  omnitest(correctExpr='AIC(fit)')
  Hint: Enter AIC(fit) at the command prompt.
  
#28
- Class: text
  Output: AIC is particularly useful when comparing two models.  Lower is better.  

#29
- Class: text
  Output: In fact, AIC is one of the criteria that is used in the automated stepwise model selection procedures in R.  Suppose we wanted to use the stepwise approach to find the best model to predict Weight from the variables in the data set.  
  
#30
- Class: cmd_question
  Output: We first must specify a "full" model - one that contains all of the potential independent variables under consideration.  This can be done by typing them individually in the model specification, or, if there are no extraneous variables in the data set, it can be specified easily as follows.  full <- lm(Weight~.,data=HealthExam)  Enter this at the command prompt. 
  CorrectAnswer: full <- lm(Weight~.,data=HealthExam)
  AnswerTests:  omnitest(correctExpr='full <- lm(Weight~.,data=HealthExam)')
  Hint: Enter full <- lm(Weight~.,data=HealthExam) at the command prompt.
  
#31
- Class: cmd_question
  Output: Enter step(full,direction="backward") at the command prompt to conduct a backward stepwise search for the model with the lowest AIC. 
  CorrectAnswer: step(full,direction="backward")
  AnswerTests:  omnitest(correctExpr='step(full,direction="backward")')
  Hint: Enter step(full,direction="backward") at the command prompt.

#32
- Class: text
  Output: Whoa!  That's a lot of output!!  You'll definitely need to scroll back to see it all.  The last model printed is the stopping point and the one selected by this procedure. 
  
#33
- Class: text
  Output: The stepwise search for the model with the lowest AIC can be done "backward", "forward", or "both".  The default is "both".  

#34
- Class: cmd_question
  Output: Another automated model selection procedure in R is one that checks all models with a given number of predictors and ranks them within each subset.  For this example, begin the procedure by entering allmods <- regsubsets(Weight~.,nvmax=4,data=HealthExam) at the command prompt.
  CorrectAnswer: allmods <- regsubsets(Weight~.,nvmax=4, data=HealthExam)
  AnswerTests:  omnitest(correctExpr='allmods <- regsubsets(Weight~.,nvmax=4,data=HealthExam)')
  Hint: Enter allmods <- regsubsets(Weight~.,nvmax=4,data=HealthExam) at the command prompt.
  
#35
- Class: cmd_question
  Output: To see some results enter summary(allmods) at the command prompt.
  CorrectAnswer: summary(allmods)
  AnswerTests:  omnitest(correctExpr='summary(allmods)')
  Hint: Enter summary(allmods) at the command prompt.

#36
- Class: text
  Output: In each row, the variables with the asterisks are the ones that produces the "best" model with the number of independent variables corresponding to the row number. 
  
#37
- Class: cmd_question
  Output: To see results based on the Adjusted R-square enter summary(allmods)$adjr2 at the command prompt.
  CorrectAnswer: summary(allmods)$adjr2
  AnswerTests:  omnitest(correctExpr='summary(allmods)$adjr2')
  Hint: Enter summary(allmods)$adjr2 at the command prompt.

#38
- Class: text
  Output: No frills output here.  The numbers are the Adjusted R-square values for each of the 4 models, in order.
  
#39
- Class: cmd_question
  Output: To see a cool summary plot that identifies models based on the Adjusted R-square enter plot(allmods, scale="adjr2") at the command prompt.
  CorrectAnswer: plot(allmods, scale="adjr2")
  AnswerTests:  omnitest(correctExpr='plot(allmods, scale="adjr2")')
  Hint: Enter plot(allmods, scale="adjr2") at the command prompt.

#40
- Class: text
  Output: The variable darkened in each row are the ones entered into the top model for that number of predictors. Mallow's Cp and Schwart's Information Criterion (BIC) is produced in the regsubsets function as well.  When this lesson is over, type ?regsubsets and also ?step to read more about these automated procedures.

#41
- Class: text
  Output: And we have come to the end of another magnificent lesson.  Farewell!

